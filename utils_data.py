'''this module contains functions for data preprocessing'''
import pickle
from datetime import datetime
import pandas as pd
from sklearn.model_selection import train_test_split  # for splitting the data into train and test samples
from sklearn.preprocessing import MinMaxScaler  # for feature scaling
from sklearn.preprocessing import OrdinalEncoder  # to encode categorical variables
import matplotlib.pyplot as plt
from ydata_profiling import ProfileReport


def plot_results(trials, task, algo):
    f, ax = plt.subplots(1)  # , figsize=(10,10))
    xs = [t['misc']['vals']['n_neighbors'] for t in trials.trials]
    ys = [-t['result']['loss'] for t in trials.trials]
    ax.scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5)
    ax.set_title( str(task) + ' - ' + str(algo), fontsize=18)
    ax.set_xlabel('n_neighbors', fontsize=12)
    ax.set_ylabel('cross validation accuracy', fontsize=12)
    print('saving plot...')
    plt.savefig('training_loss_n_neigh.png')


# test function that evaluates the model on the test data and return the score
def test(model, test_data, test_label):
    # Make a prediction using the optimized model
    prediction = model.predict( test_data )
    # Report the accuracy of the classifier on a given set of data
    score = model.score( test_data, test_label )
    return score


def transform(df, aps):
    # Do Min-Max scaling
    scaler = MinMaxScaler()
    # fit transform all the AP columns
    df[aps] = df[aps].fillna(100)
    df[aps] = scaler.fit_transform(df[aps])
    df['coord_x'] = scaler.fit_transform(df[['coord_x']])
    df['coord_y'] = scaler.fit_transform(df[['coord_y']])
    enc = OrdinalEncoder()  # select the encoder
    df['building'] = enc.fit_transform(df[['building']])  # encode categorical values
    df['floor'] = enc.fit_transform(df[['floor']])
    df['tile'] = enc.fit_transform(df[['tile']])
    # drop the rows with missing values
    df = df.dropna()
    return df


# save function save the model
def save(model, task):
    # Save the model
    print('Saving model...')
    # timestamp datetime
    date = datetime.now()
    ts = date.timestamp()
    ts = str(ts).split('.')[0]
    name_model_f = 'model_'+str(ts)+str(task)
    with open(name_model_f+'.pkl', 'wb') as f:
        pickle.dump(model, f)
    f.close()
    return name_model_f


# load function load the model
def load(model_path):
    # Load the model
    print('Loading model from {}...'.format(model_path))
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    return model


def preprocess(df, aps):
    # min-max scaling and ordinal encoding data
    df = transform(df, aps)
    # split
    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)
    return df_train, df_test


# funtion create_report use pandas-profiling to create reduced report and save it as html7
def create_report(df):
    report = ProfileReport(df,
                           title='Your Autogenerated Prediction Report', html={'style':{'full_width':True}},
                           explorative=True,
                           minimal=True
                           )

    report.to_file("report.html")


def save_excel(final_res, metrics_df):
    with pd.ExcelWriter('final_results.xlsx') as writer:
        final_res.to_excel(writer, sheet_name='final_results')
        metrics_df.to_excel(writer, sheet_name='metrics')
